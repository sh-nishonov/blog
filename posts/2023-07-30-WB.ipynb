{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /MLOps/Weights&Biases/2023/07/30/WB\n",
    "author: Shohjahon Nishonov\n",
    "branch: master\n",
    "categories:\n",
    "- MLOps\n",
    "- Weights&Biases\n",
    "date: '2023-07-30'\n",
    "hide: false\n",
    "image: wb.jpg\n",
    "output-file: 2023-07-30-wb.html\n",
    "title: Weights and Biases - A minimum for logging and experiment tracking\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acb7ce-2c4e-4555-a055-5fc9b22aceaf",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Experiment tracking is a vital step in a modern machine learning, as without it it would be difficult to compare results and choose best parameters for our models. Here, I will show the minimum to track experiments with the help of [Weights&Biases](https://wandb.ai/site\"\")(I will refer to it as *WandB*).\n",
    "\n",
    "## So what is *WandB*?\n",
    "\n",
    "WandB is a machine learning platform not only for keeping track of your hyperparameters, system metrics, and predictions so you can compare models, but also it enables to create ML workflows, version dataset and models, optimize hyperparameters and monitor models in production. It has several competitors. Namely, *mlflow* is one of the most famous ones. However, personally, I found it easier to set up and run WandB than mlflow. Moreover, it has a free tier plan, which is more than enough for personal needs.\n",
    "\n",
    "First of all, you need to register an account there, and after that go to the **User Settings** and under the API keys you will find your key to interact with the service.\n",
    "\n",
    "Then, you need to install WandB itself locally with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b1566",
   "metadata": {},
   "source": [
    "Now, launch your favourite IDE (I would suggest jupyter-lab/jupyter notebook for prototyping) and connect to your dashboard with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login['YOUR API KEY HERE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ccc37",
   "metadata": {},
   "source": [
    "There are 5 key commands in order to work with WandB: <br>\n",
    "1. wandb.login() - authorisation in the system<br>\n",
    "2. wandb.init() - new experiment initialization<br>\n",
    "3. wandb.log() - logging metrics<br>\n",
    "4. wandb.log_artifact() - logging artifacts<br>\n",
    "5. wandb.finish() - finishing experiment<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d4794",
   "metadata": {},
   "source": [
    "We will look into all these commands with the help of XGBoost example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c65da5",
   "metadata": {},
   "source": [
    "First, we'll import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5dd19",
   "metadata": {},
   "source": [
    "Then, we will write configuration for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288356bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = dict(\n",
    "    n_splits = 5,\n",
    "    random_seed = 42,\n",
    "    #params for the model\n",
    "    objective = \"binary:logistic\",\n",
    "    tree_method = \"hist\",\n",
    "    n_estimators=200,\n",
    "    early_stopping=20,\n",
    "\n",
    "    # regularization\n",
    "    max_depth=5,\n",
    "    max_delta_step=17,\n",
    "    colsample_bytree=0.632831510106799,\n",
    "    colsample_bylevel=0.6390056763292044,\n",
    "    eta=0.487396497096089,\n",
    "    min_child_weight = 1,\n",
    "    gamma = 0.25490782392352085,\n",
    "    reg_lambda = 59.960195187994934,\n",
    "    reg_alpha = 8.529168659942826,\n",
    "    scale_factor=4.71\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8112445",
   "metadata": {},
   "source": [
    "Some training code with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "scores = []\n",
    "scores_eval = []\n",
    "#X = X_train.drop(cols2drop, axis=1)\n",
    "\n",
    "wandb.init(project=\"Project Name\",\n",
    "           config=Config,\n",
    "          group=\"xgboost\",\n",
    "          job_type=\"train\",\n",
    "          name = \"Training with parameters suggested with optuna with additional feats\")\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=Config[\"n_splits\"], shuffle=True, random_state=Config[\"random_seed\"])\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    es = EarlyStopping(\n",
    "    rounds=Config[\"early_stopping\"],\n",
    "    min_delta=1e-3,\n",
    "    save_best=True,\n",
    "    maximize=True,\n",
    "    data_name=\"validation_0\",\n",
    "    metric_name=\"auc\",\n",
    ")\n",
    "    \n",
    "    clf = XGBClassifier(tree_method=Config[\"tree_method\"],\n",
    "            n_estimators=Config[\"n_estimators\"],\n",
    "            max_depth=Config[\"max_depth\"],\n",
    "            scale_pos_weight=Config[\"scale_factor\"],\n",
    "            max_delta_step=Config[\"max_delta_step\"],\n",
    "            colsample_bytree=Config[\"colsample_bytree\"],\n",
    "            colsample_bylevel=Config[\"colsample_bylevel\"],\n",
    "            learning_rate=Config[\"eta\"],\n",
    "            min_child_weight = Config[\"min_child_weight\"],\n",
    "            gamma = Config[\"gamma\"],\n",
    "            reg_lambda = Config[\"reg_lambda\"],\n",
    "            reg_alpha = Config[\"reg_alpha\"],\n",
    "            enable_categorical=True,\n",
    "            objective=Config[\"objective\"],\n",
    "            eval_metric=\"auc\",\n",
    "            random_seed=Config[\"random_seed\"],\n",
    "            callbacks=[es])\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    clfs.append(clf)\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=10)\n",
    "    preds = clf.predict(X_valid) \n",
    "    auc_valid = roc_auc_score(y_valid, preds)\n",
    "    wandb.log({\"Valid AUC\": auc_valid})\n",
    "    scores_eval.append(auc_valid)\n",
    "    print(f\"Valid AUC {auc_valid}\")\n",
    "    \n",
    "    \n",
    "    wandb.log({'Train AUC': np.mean([v for k, v in clf.evals_result()[\"validation_0\"].items() if \"auc\" in k], dtype=\"float16\")})\n",
    "    scores.append(np.mean([v for k, v in clf.evals_result()[\"validation_0\"].items() if \"auc\" in k], dtype=\"float16\")) \n",
    "\n",
    "\n",
    "mean_score = np.mean(scores, dtype=\"float16\") - np.std(scores, dtype=\"float16\")\n",
    "\n",
    "print(\"mean AUC score --------->\", mean_score)\n",
    "print(f\"mean valid AUC score {np.mean(scores_eval, dtype='float16') - np.std(scores_eval, dtype='float16')}\")\n",
    "\n",
    "wandb.log({\"Mean AUC\": mean_score, \"Mean AUC valid\": np.mean(scores_eval)})\n",
    "\n",
    "\n",
    "clf.save_model(\"xgb_classificator.json\")\n",
    "\n",
    "artifact = wandb.Artifact(name='best_XGBoost', type='model')\n",
    "artifact.add_file('xgb_classificator.json')\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7479fc",
   "metadata": {},
   "source": [
    "With the wandb.init() method we define our parameters for WandB. Namely,<br>\n",
    "`project` parameter is for the project name<br>\n",
    "`config` parameter is for the model config<br>\n",
    "`group` is for your group of models<br>\n",
    "`job_type` is whether your model is in training mode or inference<br>\n",
    "`name` is for your experiment name<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdabd87",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "I suggest giving meaningful name for your experimentation name, because it would be easier to find the right one among other experiments.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce7d25",
   "metadata": {},
   "source": [
    "With `wandb.log()` you can track any metric. It should be in a python's `dictype` data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03e86f",
   "metadata": {},
   "source": [
    "WandB artifacts is a way to save your input/output data and model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6abee",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "1. Create an empty artifact with `wandb.Artifact()`\n",
    "2. Add your model file or other files with `wandb.add_file()`\n",
    "3. Call `wandb.log_artifact()` to save your files.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199374e",
   "metadata": {},
   "source": [
    "Finally, finish logging with `wandb.finish()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad35cf",
   "metadata": {},
   "source": [
    "I hope, this small article help you to start using Weights and Biases.\n",
    "For more information about artifacts refer to this [Colab notebook](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W%26B_Artifacts.ipynb#scrollTo=IesdgHebZHcb).\n",
    "And [link for official documenation](https://docs.wandb.ai/) and [examples](https://github.com/wandb/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95070d-4f8c-4982-8cfa-0668fd3dab4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
